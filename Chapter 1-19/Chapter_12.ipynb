{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4d1c164",
   "metadata": {},
   "source": [
    "# Chapter 12: Custom Models and Training with TensorFlow\n",
    "\n",
    "Notebook ini merupakan hasil reproduksi dan penjelasan teori dari **Bab 12 - Custom Models and Training with TensorFlow** dari buku *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow (2nd Edition)* oleh AurÃ©lien GÃ©ron.\n",
    "\n",
    "ðŸ“Œ Bab ini menjelaskan cara membuat model kustom menggunakan TensorFlow (beyond Keras Sequential/Functional API), termasuk subclassing model dan training loop manual.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceb9b29",
   "metadata": {},
   "source": [
    "## Ringkasan Teori Bab 12: Custom Models and Training with TensorFlow\n",
    "\n",
    "### 1. Mengapa Perlu Model Kustom?\n",
    "\n",
    "Walau Keras sangat fleksibel, terkadang kita perlu:\n",
    "- Model kompleks dengan logika dinamis\n",
    "- Kontrol penuh terhadap training loop\n",
    "- Mengimplementasikan arsitektur eksperimental (misalnya GAN, Attention)\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Subclassing Model\n",
    "\n",
    "Alih-alih menggunakan `Sequential` atau `Functional API`, kita dapat membuat class kustom yang menurunkan `keras.Model`.\n",
    "\n",
    "```python\n",
    "class MyModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1 = keras.layers.Dense(10, activation=\"relu\")\n",
    "        self.out = keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        return self.out(x)\n",
    "```\n",
    "\n",
    "Keuntungan:\n",
    "- Lebih fleksibel\n",
    "- Bisa menambahkan loop, cabang, logika kondisi\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Subclassing Layer\n",
    "\n",
    "Mirip seperti subclassing model, kita juga bisa membuat custom layer dengan mewarisi `keras.layers.Layer`.\n",
    "\n",
    "```python\n",
    "class MyLayer(keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(...)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.kernel)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Training Loop Manual\n",
    "\n",
    "Dengan subclassed model, kita juga bisa menulis loop training secara manual.\n",
    "\n",
    "Langkah umum:\n",
    "1. Gunakan `tf.GradientTape()` untuk menghitung gradien\n",
    "2. Terapkan optimizer\n",
    "3. Update metrik\n",
    "4. Loop sendiri per batch atau epoch\n",
    "\n",
    "```python\n",
    "with tf.GradientTape() as tape:\n",
    "    y_pred = model(X_batch)\n",
    "    loss = loss_fn(y_batch, y_pred)\n",
    "grads = tape.gradient(loss, model.trainable_variables)\n",
    "optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Custom Training Step dalam Model\n",
    "\n",
    "Agar tetap bisa pakai `model.fit()`, kita bisa override `train_step()` dalam subclass model.\n",
    "\n",
    "```python\n",
    "class MyModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        X, y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(X, training=True)\n",
    "            loss = self.compiled_loss(y, y_pred)\n",
    "        grads = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Logging dan TensorBoard\n",
    "\n",
    "Training loop manual bisa disambungkan ke TensorBoard dengan `tf.summary`.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Tips Penting\n",
    "\n",
    "- `build()` hanya dipanggil sekali dan cocok untuk inisialisasi berat\n",
    "- Gunakan `self.add_weight()` untuk manajemen parameter otomatis\n",
    "- Selalu pastikan `call()` konsisten dengan mode `training=True/False`\n",
    "- Hindari loop keras jika bisa ditulis sebagai layer komposit\n",
    "\n",
    "---\n",
    "\n",
    "Bab ini adalah pengantar penting menuju fleksibilitas penuh TensorFlow untuk eksperimen deep learning tingkat lanjut ðŸš€\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba10ce9",
   "metadata": {},
   "source": [
    "## Implementasi Custom Model + Training Loop\n",
    "\n",
    "Kita akan menggunakan dataset Iris dan membuat custom model `MyModel` dengan 2 dense layer, lalu melakukan training **secara manual** menggunakan `tf.GradientTape`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f7217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load dan siapkan data\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "y_cat = to_categorical(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(100).batch(16)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038df4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclassed model\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(16, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(3, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        return self.dense2(x)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c360b6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer dan loss function\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "test_acc_metric = tf.keras.metrics.CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b50ad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual training loop\n",
    "EPOCHS = 50\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for step, (x_batch, y_batch) in enumerate(train_ds):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch, training=True)\n",
    "            loss_value = loss_fn(y_batch, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        train_acc_metric.update_state(y_batch, logits)\n",
    "\n",
    "    train_acc = train_acc_metric.result()\n",
    "    print(f\" - Train accuracy: {train_acc:.4f}\")\n",
    "    train_acc_metric.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e048cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluasi pada test set\n",
    "for x_batch_test, y_batch_test in test_ds:\n",
    "    test_logits = model(x_batch_test, training=False)\n",
    "    test_acc_metric.update_state(y_batch_test, test_logits)\n",
    "\n",
    "test_acc = test_acc_metric.result()\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61f6d64",
   "metadata": {},
   "source": [
    "### Penjelasan Kode:\n",
    "- `MyModel` adalah subclass dari `tf.keras.Model` dengan dua layer.\n",
    "- Training dilakukan **manual per batch** menggunakan `tf.GradientTape` untuk melacak dan menerapkan gradien.\n",
    "- Kita tetap bisa pakai metrik Keras seperti `CategoricalAccuracy`.\n",
    "- Metode ini memberi **kontrol penuh** atas training (misal: logika khusus, multiple optimizers, penyesuaian loss).\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
