{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c62156b",
   "metadata": {},
   "source": [
    "# Chapter 16: Neural Network Fundamentals\n",
    "\n",
    "Notebook ini merupakan hasil reproduksi dan penjelasan teori dari **Bab 16 - Neural Network Fundamentals** dari buku *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow (2nd Edition)* oleh AurÃ©lien GÃ©ron.\n",
    "\n",
    "ðŸ“Œ Bab ini memberikan dasar matematis dan intuitif dari neural networks, termasuk fungsi aktivasi, arsitektur feedforward, dan proses training dengan backpropagation.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9318979",
   "metadata": {},
   "source": [
    "## Ringkasan Teori Bab 16: Neural Network Fundamentals\n",
    "\n",
    "### 1. Neuron Buatan\n",
    "\n",
    "Neuron buatan menerima input numerik dan menghitung output dengan:\n",
    "```python\n",
    "z = w1*x1 + w2*x2 + ... + wn*xn + b\n",
    "a = activation(z)\n",
    "```\n",
    "\n",
    "- `w`: bobot (weights)\n",
    "- `x`: fitur input\n",
    "- `b`: bias\n",
    "- `a`: aktivasi (output)\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Fungsi Aktivasi\n",
    "\n",
    "#### a. ReLU (Rectified Linear Unit)\n",
    "```python\n",
    "f(z) = max(0, z)\n",
    "```\n",
    "- Populer untuk hidden layer\n",
    "- Cepat dihitung, mempercepat konvergensi\n",
    "\n",
    "#### b. Sigmoid\n",
    "```python\n",
    "f(z) = 1 / (1 + exp(-z))\n",
    "```\n",
    "- Cocok untuk output binary classification\n",
    "- Rentan terhadap vanishing gradient\n",
    "\n",
    "#### c. Tanh\n",
    "```python\n",
    "f(z) = (exp(z) - exp(-z)) / (exp(z) + exp(-z))\n",
    "```\n",
    "- Output antara -1 dan 1\n",
    "- Lebih kuat daripada sigmoid untuk hidden layer\n",
    "\n",
    "#### d. Softmax\n",
    "- Digunakan di output layer untuk multiclass classification\n",
    "- Mengubah skor menjadi probabilitas yang dijumlahkan ke 1\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Feedforward Neural Network\n",
    "\n",
    "- Layer-layer saling terhubung maju dari input ke output\n",
    "- Tidak ada loop (tidak seperti RNN)\n",
    "\n",
    "Contoh arsitektur:\n",
    "```\n",
    "Input -> Dense -> ReLU -> Dense -> Softmax\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Backpropagation\n",
    "\n",
    "- Algoritma untuk menghitung gradien loss terhadap bobot\n",
    "- Menggunakan **chain rule** dari kalkulus\n",
    "- Backprop dilakukan layer per layer dari output ke input\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Loss Function\n",
    "\n",
    "- Untuk regresi: MSE (Mean Squared Error)\n",
    "- Untuk klasifikasi: Binary crossentropy / Categorical crossentropy\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Gradient Descent\n",
    "\n",
    "- Metode untuk memperbarui bobot menggunakan gradien:\n",
    "```python\n",
    "w = w - learning_rate * gradient\n",
    "```\n",
    "\n",
    "Varian:\n",
    "- SGD\n",
    "- Momentum\n",
    "- RMSProp\n",
    "- Adam (gabungan momentum + RMS)\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Epoch dan Batch\n",
    "\n",
    "- **Epoch**: satu iterasi lengkap terhadap seluruh dataset\n",
    "- **Batch size**: jumlah contoh yang digunakan sebelum update bobot\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Evaluasi Model\n",
    "\n",
    "- Accuracy, Precision, Recall, F1-score untuk klasifikasi\n",
    "- RMSE, MAE untuk regresi\n",
    "\n",
    "---\n",
    "\n",
    "ðŸ“Œ Ringkasan:\n",
    "Bab ini menyatukan teori matematis dan pemrograman dasar neural network yang menjadi fondasi untuk model deep learning yang lebih kompleks.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65525348",
   "metadata": {},
   "source": [
    "## Implementasi Neural Network Sederhana\n",
    "\n",
    "Kita akan membangun dan melatih neural network feedforward dengan:\n",
    "- 1 hidden layer (ReLU)\n",
    "- 1 output layer (Softmax)\n",
    "- Dataset: `Iris` (multiclass classification)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4cfb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "y_cat = to_categorical(y)\n",
    "\n",
    "# Preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb24d1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat model sederhana\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(10, activation='relu', input_shape=(4,), name=\"hidden_layer\"),\n",
    "    keras.layers.Dense(3, activation='softmax', name=\"output_layer\")\n",
    "])\n",
    "\n",
    "# Kompilasi model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Ringkasan arsitektur\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45efed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_split=0.1, verbose=0)\n",
    "\n",
    "# Evaluasi\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aea885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi loss dan akurasi\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.title(\"Accuracy per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title(\"Loss per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac881b4",
   "metadata": {},
   "source": [
    "### Penjelasan:\n",
    "- Dataset **Iris** dipakai karena cocok untuk klasifikasi 3 kelas.\n",
    "- Model memiliki 1 hidden layer (ReLU) dan 1 output layer (Softmax).\n",
    "- Visualisasi training menunjukkan proses pembelajaran model selama 30 epoch.\n",
    "\n",
    "ðŸ“Œ Ini adalah contoh dasar dari feedforward neural network â€” pondasi model deep learning seperti CNN, RNN, dan lainnya.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
