{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "623f0900",
   "metadata": {},
   "source": [
    "# Chapter 4: Training Models\n",
    "\n",
    "Notebook ini merupakan hasil reproduksi dan penjelasan teori dari **Bab 4 - Training Models** dari buku *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow (2nd Edition)* oleh AurÃ©lien GÃ©ron.\n",
    "\n",
    "ðŸ“Œ Fokus utama bab ini adalah membahas regresi linier, cost function, gradient descent, dan model linear lainnya seperti Ridge dan Lasso Regression.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c580b5",
   "metadata": {},
   "source": [
    "## Ringkasan Teori Bab 4: Training Models\n",
    "\n",
    "### 1. Regresi Linear (Linear Regression)\n",
    "Model regresi linear memprediksi output dengan rumus:\n",
    "\n",
    "\\[\n",
    "\\hat{y} = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_n x_n\n",
    "\\]\n",
    "\n",
    "- $\\hat{y}$: nilai prediksi  \n",
    "- $\\theta_j$: parameter bobot  \n",
    "- $x_i$: nilai fitur ke-$i$\n",
    "\n",
    "Untuk melatih model, kita meminimalkan cost function berupa MSE.  \n",
    "Solusi matematis langsung disebut **Normal Equation**:\n",
    "\n",
    "\\[\n",
    "\\hat{\\theta} = (X^T X)^{-1} X^T y\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Gradient Descent (GD)\n",
    "Algoritma optimisasi yang menyesuaikan parameter secara iteratif.\n",
    "\n",
    "**Jenis-jenis Gradient Descent**:\n",
    "- **Batch GD**: seluruh data â€” akurat tapi lambat\n",
    "- **Stochastic GD**: satu sampel â€” cepat tapi fluktuatif\n",
    "- **Mini-batch GD**: kombinasi keduanya\n",
    "\n",
    "> Learning rate terlalu besar = lompat-lompat, terlalu kecil = lambat\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Regresi Polinomial (Polynomial Regression)\n",
    "Model linear dapat digunakan untuk data non-linear dengan menambahkan fitur berupa pangkat variabel:\n",
    "\n",
    "\\[\n",
    "x, x^2, x^3, \\dots\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Kurva Pembelajaran (Learning Curves)\n",
    "Plot error terhadap jumlah data.  \n",
    "\n",
    "- **Underfitting**: training dan validation error tinggi dan sejajar  \n",
    "- **Overfitting**: training error rendah, validation error tinggi\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Regularisasi (Model Linear Diregularisasi)\n",
    "Untuk mengurangi overfitting:\n",
    "\n",
    "- **Ridge Regression (L2)**:\n",
    "  \\[\n",
    "  J(\\theta) = \\text{MSE} + \\alpha \\sum_{i=1}^n \\theta_i^2\n",
    "  \\]\n",
    "\n",
    "- **Lasso Regression (L1)**:\n",
    "  \\[\n",
    "  J(\\theta) = \\text{MSE} + \\alpha \\sum_{i=1}^n |\\theta_i|\n",
    "  \\]\n",
    "\n",
    "- **Elastic Net**: gabungan L1 dan L2\n",
    "- **Early Stopping**: hentikan training saat validation error mulai naik\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Regresi Logistik dan Softmax\n",
    "\n",
    "**Logistic Regression** untuk binary classification:\n",
    "\\[\n",
    "\\hat{p} = \\sigma(z) = \\frac{1}{1 + e^{-z}}, \\quad z = \\theta^T x\n",
    "\\]\n",
    "\n",
    "**Softmax Regression** untuk multiclass:\n",
    "\\[\n",
    "\\hat{p}_k = \\frac{e^{s_k}}{\\sum_{j=1}^K e^{s_j}}\n",
    "\\]\n",
    "dengan $s_k = \\theta_k^T x$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d461869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cf0fca",
   "metadata": {},
   "source": [
    "## Linear Regression: Simulasi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331fd130",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)\n",
    "\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Data Linear\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c2db10",
   "metadata": {},
   "source": [
    "## Training Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5ea422",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n",
    "print(\"Intercept:\", lin_reg.intercept_)\n",
    "print(\"Slope:\", lin_reg.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5caf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[0], [2]])\n",
    "y_pred = lin_reg.predict(X_new)\n",
    "\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.plot(X_new, y_pred, \"r-\", linewidth=2, label=\"Linear Model\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Hasil Linear Regression\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ab8887",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "Gradient Descent digunakan untuk meminimalkan fungsi cost (MSE). Terdapat tiga jenis:\n",
    "- Batch Gradient Descent\n",
    "- Stochastic Gradient Descent (SGD)\n",
    "- Mini-batch Gradient Descent\n",
    "\n",
    "Scikit-Learn menggunakan solusi closed-form (`LinearRegression`) atau implementasi SGD (`SGDRegressor`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2372226d",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cc33d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(X)\n",
    "\n",
    "lin_reg_poly = LinearRegression()\n",
    "lin_reg_poly.fit(X_poly, y)\n",
    "\n",
    "X_test = np.linspace(0, 2, 100).reshape(-1, 1)\n",
    "X_test_poly = poly_features.transform(X_test)\n",
    "y_test_pred = lin_reg_poly.predict(X_test_poly)\n",
    "\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.plot(X_test, y_test_pred, \"r-\", label=\"Polynomial Model\")\n",
    "plt.title(\"Polynomial Regression\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
