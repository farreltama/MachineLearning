{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b18eab84",
   "metadata": {},
   "source": [
    "# Chapter 17: Custom Training with TensorFlow\n",
    "\n",
    "Notebook ini merupakan hasil reproduksi dan penjelasan teori dari **Bab 17 - Custom Training with TensorFlow** dari buku *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow (2nd Edition)* oleh AurÃ©lien GÃ©ron.\n",
    "\n",
    "ðŸ“Œ Bab ini menjelaskan cara melakukan proses training secara manual (low-level) menggunakan GradientTape, loss custom, loop training kustom, dan kontrol penuh terhadap update parameter.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96a3aea",
   "metadata": {},
   "source": [
    "## Ringkasan Teori Bab 17: Custom Training with TensorFlow\n",
    "\n",
    "### 1. Kapan Butuh Custom Training?\n",
    "\n",
    "- Saat kita butuh **kontrol penuh** atas proses training\n",
    "- Misalnya untuk:\n",
    "  - Logging dan metrik kustom\n",
    "  - Update parameter secara berbeda per layer\n",
    "  - Perhitungan loss khusus\n",
    "\n",
    "---\n",
    "\n",
    "### 2. GradientTape\n",
    "\n",
    "`tf.GradientTape()` digunakan untuk merekam operasi agar kita bisa menghitung gradien secara eksplisit.\n",
    "\n",
    "```python\n",
    "with tf.GradientTape() as tape:\n",
    "    y_pred = model(x_batch)\n",
    "    loss = loss_fn(y_batch, y_pred)\n",
    "grads = tape.gradient(loss, model.trainable_variables)\n",
    "optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Membuat Loop Training Manual\n",
    "\n",
    "Langkah utama dalam training loop:\n",
    "1. Ambil batch dari dataset\n",
    "2. Hitung prediksi dan loss\n",
    "3. Hitung gradien dengan `GradientTape`\n",
    "4. Update bobot menggunakan `optimizer`\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Custom Loss Function\n",
    "\n",
    "Kita bisa membuat fungsi loss sendiri:\n",
    "```python\n",
    "def custom_mse(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "```\n",
    "\n",
    "Bisa dipakai langsung saat compile model:\n",
    "```python\n",
    "model.compile(loss=custom_mse, ...)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Training Step Kustom (dalam Class Model)\n",
    "\n",
    "Dengan subclassing `tf.keras.Model`, kita bisa override:\n",
    "- `train_step(self, data)`\n",
    "- `test_step(self, data)`\n",
    "- `compile(...)` tetap digunakan\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Logging dan Metric\n",
    "\n",
    "Gunakan:\n",
    "- `tf.keras.metrics.Mean()` untuk menyimpan nilai loss rata-rata\n",
    "- `reset_states()` dipanggil tiap epoch\n",
    "- `update_state()` dipanggil di setiap batch\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Checkpoint & Callback\n",
    "\n",
    "- Checkpoint manual dapat dibuat dengan `tf.train.Checkpoint`\n",
    "- Gunakan `tf.keras.callbacks.Callback` untuk logging, early stopping, dsb.\n",
    "\n",
    "---\n",
    "\n",
    "ðŸ“Œ Kesimpulan:\n",
    "Bab ini memberikan kita kekuatan untuk mengontrol proses training dari nol, cocok untuk riset atau eksperimen model yang tidak konvensional.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8f1341",
   "metadata": {},
   "source": [
    "## Implementasi Custom Training Loop\n",
    "\n",
    "Contoh ini akan menunjukkan bagaimana melakukan proses training secara manual dengan:\n",
    "- Subclassing `Model`\n",
    "- `GradientTape`\n",
    "- Logging manual metrik akurasi & loss\n",
    "\n",
    "Dataset: Iris (klasifikasi 3 kelas)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe03e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# Load dan siapkan data\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = to_categorical(iris.target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5dcbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclassing model\n",
    "class CustomIrisModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = tf.keras.layers.Dense(10, activation='relu')\n",
    "        self.output_layer = tf.keras.layers.Dense(3, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.hidden(inputs)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "model = CustomIrisModel()\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6f6443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop training manual\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(100).batch(16)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(16)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x)\n",
    "        loss = loss_fn(y, predictions)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    train_loss.update_state(loss)\n",
    "    train_accuracy.update_state(y, predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step(x, y):\n",
    "    predictions = model(x)\n",
    "    t_loss = loss_fn(y, predictions)\n",
    "    test_loss.update_state(t_loss)\n",
    "    test_accuracy.update_state(y, predictions)\n",
    "\n",
    "# Training loop\n",
    "EPOCHS = 30\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss.reset_state()\n",
    "    train_accuracy.reset_state()\n",
    "    test_loss.reset_state()\n",
    "    test_accuracy.reset_state()\n",
    "\n",
    "    for x_batch, y_batch in train_dataset:\n",
    "        train_step(x_batch, y_batch)\n",
    "\n",
    "    for x_batch, y_batch in test_dataset:\n",
    "        test_step(x_batch, y_batch)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: \"\n",
    "          f\"Train Loss={train_loss.result():.4f}, Train Acc={train_accuracy.result():.4f}, \"\n",
    "          f\"Test Loss={test_loss.result():.4f}, Test Acc={test_accuracy.result():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9794f24d",
   "metadata": {},
   "source": [
    "### Penjelasan:\n",
    "- `CustomIrisModel` adalah model kustom berbasis subclassing\n",
    "- Loop training ditulis secara manual dengan `GradientTape`\n",
    "- Kita update metrik dan optimizer secara eksplisit\n",
    "- Pendekatan ini cocok untuk riset, eksperimen loss khusus, atau arsitektur tak biasa\n",
    "\n",
    "ðŸ“Œ Perlu kontrol penuh? Gunakan pendekatan ini.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
