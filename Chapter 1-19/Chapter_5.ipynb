{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6023bd06",
   "metadata": {},
   "source": [
    "# Chapter 5: Support Vector Machines\n",
    "\n",
    "Notebook ini merupakan hasil reproduksi dan penjelasan teori dari **Bab 5 - Support Vector Machines (SVM)** dari buku *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow (2nd Edition)* oleh AurÃ©lien GÃ©ron.\n",
    "\n",
    "ðŸ“Œ Fokus bab ini adalah klasifikasi margin maksimum menggunakan Support Vector Classifier (SVC), serta konsep margin, kernel trick, dan regularisasi dalam SVM.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89a08b0",
   "metadata": {},
   "source": [
    "## Ringkasan Teori Bab 5: Support Vector Machines\n",
    "\n",
    "### 1. Konsep Dasar\n",
    "SVM bertujuan mencari hyperplane terbaik yang memisahkan dua kelas dengan **margin maksimum**.\n",
    "\n",
    "### 2. Margin\n",
    "- **Hard Margin**: memisahkan data tanpa kesalahan â€” hanya cocok untuk data yang bisa dipisahkan sempurna.\n",
    "- **Soft Margin**: memungkinkan sedikit pelanggaran (misalnya outlier) untuk menghindari overfitting.\n",
    "\n",
    "### 3. Kernel Trick\n",
    "Digunakan untuk mengubah data ke dimensi yang lebih tinggi agar bisa dipisahkan secara linear.\n",
    "\n",
    "Beberapa kernel umum:\n",
    "- Linear\n",
    "- Polynomial: $K(x, x') = (x^T x' + r)^d$\n",
    "- RBF (Gaussian): $K(x, x') = \\exp(-\\gamma ||x - x'||^2)$\n",
    "\n",
    "### 4. Hyperparameter\n",
    "- $C$: mengontrol trade-off antara margin dan error (regularisasi)\n",
    "- $\\gamma$: pada RBF kernel, mengontrol seberapa jauh pengaruh satu sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd077f44",
   "metadata": {},
   "source": [
    "## Contoh Klasifikasi dengan SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2bf86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate data\n",
    "X, y = make_moons(n_samples=100, noise=0.15, random_state=42)\n",
    "\n",
    "# Pipeline SVM dengan RBF kernel\n",
    "svm_clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm\", SVC(kernel=\"rbf\", gamma=2, C=1))\n",
    "])\n",
    "svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36064207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def plot_decision_boundary(clf, X, y, ax=None):\n",
    "    h = .02\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    ax.contourf(xx, yy, Z, alpha=0.3)\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k')\n",
    "    ax.set_title(\"Decision Boundary SVM\")\n",
    "\n",
    "plot_decision_boundary(svm_clf, X, y)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
